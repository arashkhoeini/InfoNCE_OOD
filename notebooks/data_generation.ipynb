{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Generated 50000 overlayed images with labels in the \"overlayed_mnist_cifar10_v2\" directory.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST and CIFAR-10 datasets\n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(3),  # Convert to RGB\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_cifar = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load MNIST\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_train, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load CIFAR-10\n",
    "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
    "cifar_loader = torch.utils.data.DataLoader(cifar_train, batch_size=1, shuffle=False)\n",
    "\n",
    "# Ensure the number of samples is consistent across both datasets\n",
    "n_samples = min(len(mnist_train), len(cifar_train))\n",
    "\n",
    "# Directory to save the generated dataset\n",
    "output_dir = 'overlayed_mnist_cifar10_v2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Overlay images and save them with their labels\n",
    "for i, ((mnist_img, mnist_label), (cifar_img, cifar_label)) in enumerate(zip(mnist_loader, cifar_loader)):\n",
    "    if i >= n_samples:\n",
    "        break\n",
    "    \n",
    "    # Convert CIFAR image to numpy array\n",
    "    cifar_img = cifar_img.squeeze().permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Convert MNIST image to numpy array\n",
    "    mnist_img = mnist_img.squeeze().permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Overlay the images\n",
    "    combined_image = np.clip(mnist_img + cifar_img , 0, 1)\n",
    "\n",
    "    # Convert back to image and save\n",
    "    combined_image_pil = Image.fromarray((combined_image * 255).astype(np.uint8))\n",
    "    combined_image_pil.save(os.path.join(output_dir, f'image_{i}.png'))\n",
    "\n",
    "    # Save the labels\n",
    "    with open(os.path.join(output_dir, f'label_{i}.txt'), 'w') as f:\n",
    "        f.write(f'MNIST Label: {mnist_label.item()}\\n')\n",
    "        f.write(f'CIFAR-10 Label: {cifar_label.item()}\\n')\n",
    "\n",
    "print(f'Generated {n_samples} overlayed images with labels in the \"{output_dir}\" directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Generated 10000 overlayed images with labels in the \"overlayed_mnist_cifar10_test\" directory.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST and CIFAR-10 datasets\n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(3),  # Convert to RGB\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_cifar = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load MNIST\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_test, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load CIFAR-10\n",
    "cifar_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n",
    "cifar_loader = torch.utils.data.DataLoader(cifar_test, batch_size=1, shuffle=False)\n",
    "\n",
    "# Ensure the number of samples is consistent across both datasets\n",
    "n_samples = min(len(mnist_test), len(cifar_test))\n",
    "\n",
    "# Directory to save the generated dataset\n",
    "output_dir = 'overlayed_mnist_cifar10_test'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Overlay images and save them with their labels\n",
    "for i, ((mnist_img, mnist_label), (cifar_img, cifar_label)) in enumerate(zip(mnist_loader, cifar_loader)):\n",
    "    if i >= n_samples:\n",
    "        break\n",
    "    \n",
    "    # Convert CIFAR image to numpy array\n",
    "    cifar_img = cifar_img.squeeze().permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Convert MNIST image to numpy array\n",
    "    mnist_img = mnist_img.squeeze().permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Overlay the images\n",
    "    combined_image = np.clip(mnist_img + cifar_img , 0, 1)\n",
    "\n",
    "    # Convert back to image and save\n",
    "    combined_image_pil = Image.fromarray((combined_image * 255).astype(np.uint8))\n",
    "    combined_image_pil.save(os.path.join(output_dir, f'image_{i}.png'))\n",
    "\n",
    "    # Save the labels\n",
    "    with open(os.path.join(output_dir, f'label_{i}.txt'), 'w') as f:\n",
    "        f.write(f'MNIST Label: {mnist_label.item()}\\n')\n",
    "        f.write(f'CIFAR-10 Label: {cifar_label.item()}\\n')\n",
    "\n",
    "print(f'Generated {n_samples} overlayed images with labels in the \"{output_dir}\" directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "dir = Path('overlayed_mnist_cifar10_test')\n",
    "image_ids = []\n",
    "mnist_labels = []\n",
    "cifar10_labels = []\n",
    "for file in dir.iterdir():\n",
    "    if file.is_file():\n",
    "        if 'label' in file.name:\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                mnist_label = int(lines[0].split()[-1])\n",
    "                cifar10_label = int(lines[1].split()[-1])\n",
    "            image_ids.append(file.name.split('_')[1].split('.')[0])\n",
    "            mnist_labels.append(mnist_label)\n",
    "            cifar10_labels.append(cifar10_label)\n",
    "\n",
    "pd.DataFrame({'image_id': image_ids, 'mnist_label': mnist_labels, 'cifar10_label': cifar10_labels}).to_csv('overlayed_mnist_cifar10_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2) (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_dir = 'overlayed_mnist_cifar10_train'\n",
    "labels = pd.read_csv(Path(image_dir) / 'labels.csv')\n",
    "labels = labels.sort_values(by='image_id').set_index('image_id')\n",
    "\n",
    "# Combine the two categories into a single multi-class label\n",
    "labels['combined_label'] = labels.apply(lambda row: f\"{row['mnist_label']}_{row['cifar10_label']}\", axis=1)\n",
    "\n",
    "# Split the dataset into train and validation sets with stratification\n",
    "train_labels, val_labels = train_test_split(\n",
    "    labels,\n",
    "    test_size=10000,\n",
    "    stratify=labels['combined_label'],\n",
    ")\n",
    "\n",
    "# Drop the combined label column\n",
    "train_labels = train_labels.drop(columns=['combined_label'])\n",
    "val_labels = val_labels.drop(columns=['combined_label'])\n",
    "\n",
    "print(train_labels.shape, val_labels.shape)\n",
    "# now remove image_ids that are in train_labels from data_dir and move them to val_dir\n",
    "import shutil\n",
    "for image_id in val_labels.index:\n",
    "    shutil.move(Path(image_dir) / f'image_{image_id}.png', 'overlayed_mnist_cifar10_val')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels.to_csv('overlayed_mnist_cifar10_val/labels.csv')\n",
    "# same for train set\n",
    "train_labels.to_csv('overlayed_mnist_cifar10_train/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.57580509 0.56986527 0.53811235]\n",
      "Std: [0.25580952 0.25461894 0.26496579]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_mean_std(image_dir):\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.startswith('image_')]\n",
    "    mean = np.zeros(3)\n",
    "    std = np.zeros(3)\n",
    "    num_images = len(image_files)\n",
    "\n",
    "    for image_file in tqdm(image_files):\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = np.array(image) / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        mean += image.mean(axis=(0, 1))\n",
    "        std += image.std(axis=(0, 1))\n",
    "\n",
    "    mean /= num_images\n",
    "    std /= num_images\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# image_dir = 'overlayed_mnist_cifar10_train'\n",
    "# mean, std = calculate_mean_std(image_dir)\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet18 = models.resnet18()\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
